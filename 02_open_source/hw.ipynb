{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "043fb5fb-4b05-4026-a7d9-d3e5551741a4",
   "metadata": {},
   "source": [
    "# Q&A json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d43546-896f-43b6-bf44-4ac0ff896a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rollylevente/miniconda3/envs/devenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e310e1-9137-48b1-8e5f-417fceecb374",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1263008c-3278-433d-bcd5-eb12d1194a02",
   "metadata": {},
   "source": [
    "1. create or start docker \n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    -v ollama:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama\n",
    "or\n",
    "$docker run -it <image_name> \n",
    "\n",
    "2. execute docker bash -> $docker exec -it <container_name> bash\n",
    "\n",
    "3. ollama --version\n",
    "0.1.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4d358-b8f9-4172-bce5-feea602fcf85",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c4e3d69-64f7-499d-af79-5d005cf56e67",
   "metadata": {},
   "source": [
    "1. $ollama pull gemma:2b\n",
    "2. $cd root/.ollama/models/manifests/registry.ollama.ai/library\n",
    "3. $cat 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678edcb-a115-4539-9076-2916b615d9a0",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c5198b-1e00-43ad-9f47-abf93cb78a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Configure the OpenAI client\n",
    "client = openai.OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0ed53f-0703-419c-9c9f-0995b959e0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, 10 * 10 = 100.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define your prompt\n",
    "#prompt = \"What is the capital of France?\"\n",
    "prompt = \"10 * 10?\"\n",
    "\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4af8e-b8c9-49d3-8926-31e2bcfbce9a",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4233acaa-c8b6-4e9d-8954-b4c835a824d2",
   "metadata": {},
   "source": [
    "1. $mkdir ollama_files\n",
    "\n",
    "2. $docker run -it \\\n",
    "    --rm \\\n",
    "    -v ./ollama_files:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama2 \\\n",
    "    ollama/ollama\n",
    "\n",
    "3. $docker exec -it ollama ollama pull gemma:2b \n",
    "4. $du -h \n",
    "1.7GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f9aa5-0fc8-40b2-b632-a83fbff83227",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbbe73-6b66-42a0-a182-7544ddb4e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM ollama/ollama\n",
    "\n",
    "COPY ollama_files /root/.ollama\n",
    "\n",
    "--> ollama_files /root/.ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ce9d0-f138-4469-a3e2-a1ed37ff5c2e",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea07f025-434e-4e14-a2f1-e07b94b50fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's the formula for energy:\n",
      "\n",
      "**E = K + U**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **E** is the energy in joules (J)\n",
      "* **K** is the kinetic energy in joules (J)\n",
      "* **U** is the potential energy in joules (J)\n",
      "\n",
      "**Kinetic energy (K)** is the energy an object possesses when it moves or is in motion. It is calculated as half the product of an object's mass (m) and its velocity (v) squared:\n",
      "\n",
      "**K = 1/2 * m * v^2**\n",
      "\n",
      "**Potential energy (U)** is the energy an object possesses when it is in a position or has a specific configuration. It is calculated as the product of an object's mass and the gravitational constant (g) multiplied by the height or distance of the object from a reference point.\n",
      "\n",
      "**Gravitational potential energy (U)** is given by the formula:\n",
      "\n",
      "**U = mgh**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **m** is the mass of the object in kilograms (kg)\n",
      "* **g** is the acceleration due to gravity in meters per second squared (m/s^2)\n",
      "* **h** is the height or distance of the object in meters (m)\n",
      "\n",
      "The formula for energy can be used to calculate the total energy of an object, the energy of a specific part of an object, or the change in energy of an object over time.\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Configure the OpenAI client\n",
    "client = openai.OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        temperature=0.0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def count_tokens(text):\n",
    "    tokens = text.split()\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "prompt = \"What's the formula for energy?\"\n",
    "answer = llm(prompt)\n",
    "print(answer)\n",
    "print(count_tokens(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "devenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
